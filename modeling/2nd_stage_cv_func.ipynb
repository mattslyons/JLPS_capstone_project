{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Create a function that can be used in the 2nd stage regression to perform a time series cross validation. \n",
    "- Using an expanding window cross validation\n",
    "\n",
    "\n",
    "The 2nd stage regression predicts the medical outcomes using the predicted PM2.5 (and separately with the actual pm2.5), as well as the same fixed effects from the first stage regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional. I'm getting annoying warnings that I just want to ignore:\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# basics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import requests\n",
    "import urllib\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "# modeling\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep this as false unless you want to save out the fitted model objects and results \n",
    "save_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Path\n",
    "\n",
    "Add a new elif section for your path if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local or gdrive\n",
    "path_source = 'work'\n",
    "\n",
    "if path_source == 'gdrive':\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  data_path = '/content/gdrive/MyDrive/Classes/W210_capstone/W210_Capstone/Data'\n",
    "  fitted_models_path = '/content/gdrive/MyDrive/Classes/W210_capstone/W210_Capstone/fitted_models/2022-10-23'\n",
    "  \n",
    "elif path_source == 'local':\n",
    "  data_path = '/Users/tj/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/Data'\n",
    "  fitted_models_path = '/Users/tj/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/fitted_models/2022-10-23'\n",
    "\n",
    "elif path_source == 'work':\n",
    "  data_path = '/Users/trevorjohnson/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/Data'\n",
    "  fitted_models_path = '/Users/trevorjohnson/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/fitted_models/2022-10-23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our modeling data\n",
    "df = pd.read_csv(os.path.join(data_path, 'modeling_data/modeling_data_joined_11-9.csv'))\n",
    "\n",
    "# read in cornelia's healthcare data\n",
    "df1 = pd.read_csv(os.path.join(data_path, 'medical/hematopoietic_cancers.csv')).iloc[:,1:]\n",
    "df2 = pd.read_csv(os.path.join(data_path, 'medical/pediatric_vasculitis.csv')).iloc[:,1:]\n",
    "df3 = pd.read_csv(os.path.join(data_path, 'medical/type_1_diabetes.csv')).iloc[:,1:]\n",
    "df4 = pd.read_csv(os.path.join(data_path, 'medical/resp_cardio.csv')).iloc[:,1:]\n",
    "df5 = pd.read_csv(os.path.join(data_path, 'medical/injuries_accidents.csv')).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# med data:\n",
    "\n",
    "# get all distinct patzip_year_month\n",
    "all_pats = df1['patzip_year_month'].to_list() + \\\n",
    "  df2['patzip_year_month'].to_list() + \\\n",
    "  df3['patzip_year_month'].to_list() + \\\n",
    "  df4['patzip_year_month'].to_list() + \\\n",
    "  df5['patzip_year_month'].to_list() \n",
    "all_pats = list(set(all_pats))\n",
    "df_med = pd.DataFrame({'patzip_year_month': all_pats})\n",
    "\n",
    "# rename columns more intuitively\n",
    "df1 = df1.rename(columns={'number_of_visits': 'number_of_visits_hem_cancers'})\n",
    "df2 = df2.rename(columns={'number_of_visits': 'number_of_visits_vasc'})\n",
    "df3 = df3.rename(columns={'number_of_visits': 'number_of_visits_diab'})\n",
    "df4 = df4.rename(columns={'number_of_visits': 'number_of_visits_resp_cardio'})\n",
    "df5 = df5.rename(columns={'number_of_visits': 'number_of_visits_injuries'})\n",
    "\n",
    "# now join all the diagnoses on this dataset\n",
    "df_med = df_med\\\n",
    "  .merge(df1, on='patzip_year_month', how='left')\\\n",
    "  .merge(df2, on='patzip_year_month', how='left')\\\n",
    "  .merge(df3, on='patzip_year_month', how='left')\\\n",
    "  .merge(df4, on='patzip_year_month', how='left')\\\n",
    "  .merge(df5, on='patzip_year_month', how='left')\n",
    "\n",
    "# join data\n",
    "df['year_month'] = df['year_month'].map(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "df['zip_year_month'] = df['school_zip'].astype(str) + '-' +\\\n",
    "  df['year_month'].dt.year.astype(str) + '-' +\\\n",
    "  df['year_month'].dt.month.astype(str)\n",
    "\n",
    "df = pd.merge(df, df_med, left_on='zip_year_month', right_on='patzip_year_month', how='left')\n",
    "df = df.drop(columns = 'Unnamed: 0')\n",
    "\n",
    "# for missing med data, assume there were 0 cases:\n",
    "med_vars = ['hematopoietic_cancers', 'number_of_visits_hem_cancers', \n",
    "  'pediatric_vasculitis', 'number_of_visits_vasc', \n",
    "  'type_1_diabetes', 'number_of_visits_diab',\n",
    "  'resp_cardio', 'number_of_visits_resp_cardio',\n",
    "  'injuries_accidents', 'number_of_visits_injuries'\n",
    "  ]\n",
    "for var in med_vars:\n",
    "  df[var] = df[var].fillna(0)\n",
    "\n",
    "# fixing month datatype\n",
    "df['month'] = df['month'].astype(str)\n",
    "\n",
    "# Create response variables, which is visits / population\n",
    "df['y_hematopoietic'] = 1000 * df['number_of_visits_hem_cancers'] / df['total_pop_under19']\n",
    "df['y_vasculitis'] = 1000 * df['number_of_visits_vasc'] / df['total_pop_under19']\n",
    "df['y_diabetes'] = 1000 * df['number_of_visits_diab'] / df['total_pop_under19']\n",
    "df['y_resp_cardio'] = 1000 * df['number_of_visits_resp_cardio'] / df['total_pop_under19']\n",
    "df['y_injuries'] = 1000 * df['number_of_visits_injuries'] / df['total_pop_under19']\n",
    "\n",
    "# Create an option for a logged version of the treatment var (log(1+x)). this makes it normally distributed \n",
    "df['pm25_log'] = np.log1p(df['pm25'])\n",
    "\n",
    "# create year trend feature\n",
    "df['year_trend'] = df['year'] - 1999\n",
    "\n",
    "# create county_month\n",
    "df['county_month'] = df.apply(lambda df: df['month'].rjust(2, '0') + '_' + df['school_county_v2'], axis=1)\n",
    "\n",
    "# create year_month_county (in case we want to just direclty use this var for the interaction effects)\n",
    "df['year_month_county'] = df.apply(lambda df: str(df['year']) + '_' + df['month'] + '_' + df['school_county_v2'], axis=1)\n",
    "\n",
    "# no need to one hot encode anymore, b/c data is already encoded \n",
    "\n",
    "# filter data to appropriate data range\n",
    "df = df[df.year >= 2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split \n",
    "# keep 2018 as the held out test set \n",
    "df_test = df[df.year == 2018]\n",
    "df = df[df.year != 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data on date\n",
    "df = df.sort_values('year_month').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables for modeling\n",
    "date_var = 'year_month'\n",
    "num_vars = ['school_elevation_m', 'nearby_point_source_count', 'school_wspd', 'tax_liability_per_capita', 'school_temperature', 'school_count', 'pm25_r6', 'pm25_r12']\n",
    "counties = [i for i in df.columns if re.search('^school_county_v2_', i)]\n",
    "months = [i for i in df.columns if re.search ('^month_', i)]\n",
    "# potentially use county_month instead of the above \n",
    "\n",
    "xvars = num_vars + counties + months \n",
    "yvar = ['y_hematopoietic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation function\n",
    "\n",
    "Note, this function does not yet do the grid search for hyperparams, but just does the CV once. Update this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(\n",
    "  df: pd.DataFrame, \n",
    "  xvars: list, \n",
    "  yvar: str, \n",
    "  hyperparams: dict = {'max_depth': [1, 5, 10], 'subsample': [.8, 1], 'eta': [.1, .3]}, \n",
    "  search_type='grid', \n",
    "  folds=5, \n",
    "  verbose=1):\n",
    "\n",
    "  ''' \n",
    "  Inputs:\n",
    "  - df: dataframe of your training data\n",
    "  - xvars: a list of all the xvars to pass to xgboost\n",
    "  - yvar: string of your target variable\n",
    "  - verbose: optionality for diff amounts of printouts. Can be 0, 1, 2. 0 = silent, 1 = update after each fold, 2 = update after every single hyperparam combination. \n",
    "  - hyperparams: this must be a dictionary of lists. So each key is a xgb hyperparam, then it must have a list of values to tune with. \n",
    "    See the default for an example. Can put in an arbitrary number of hyperparam options. \n",
    "  \n",
    "  Output:\n",
    "  - dictionary with the following keys: ['fold', 'hyperparams', 'rmse_train', 'rmse_test']. \n",
    "  '''\n",
    "\n",
    "  # this dictionary will hold all the final results\n",
    "  final_res = {'fold':[], 'hyperparams':[], 'rmse_train': [], 'rmse_test': []}\n",
    "\n",
    "  # get only necessary fields in df\n",
    "  df = df[xvars + [yvar]]\n",
    "\n",
    "  # set up the time series split class, to do an expanding window cross fold. \n",
    "  tss = TimeSeriesSplit(n_splits=folds)\n",
    "  tss_folds = tss.split(df)\n",
    "  all_folds = [i for i in tss_folds]\n",
    "\n",
    "  # get all combinations of hyperparams\n",
    "  def expand_grid(hyperparams):\n",
    "    keys = list(hyperparams.keys())\n",
    "    hyperparams_df = pd.DataFrame(np.array(np.meshgrid(*[hyperparams[key_i] for key_i in keys])).T.reshape(-1, len(keys)))\n",
    "    hyperparams_df.columns = keys \n",
    "    return hyperparams_df\n",
    "\n",
    "  df_hyperparams = expand_grid(hyperparams)\n",
    "\n",
    "  # function to use later\n",
    "  def get_rmse(dmat_train, df_train):\n",
    "    ytrue = df_train[yvar].values.flatten()\n",
    "    yhat = booster.predict(dmat_train)\n",
    "    rmse = np.mean(((ytrue - yhat)**2)**.5)\n",
    "    return rmse \n",
    "\n",
    "  # loop over each expanding time series window\n",
    "  for fold_count,fold in enumerate(all_folds):\n",
    "    if verbose > 0:\n",
    "      print('Working on fold {}/{}'.format(fold_count+1, folds))\n",
    "\n",
    "    df_train = df.loc[fold[0]]\n",
    "    df_test = df.loc[fold[1]]\n",
    "\n",
    "    # convert to xgb types\n",
    "    dmat_train = xgb.DMatrix(df_train[xvars], df_train[yvar])\n",
    "    dmat_test = xgb.DMatrix(df_test[xvars], df_test[yvar])\n",
    "\n",
    "    # within each time series cross fold, perform a grid search with all hyperparam combinations and evaluate results. \n",
    "    if search_type == 'grid':\n",
    "      for param_set_i in range(df_hyperparams.shape[0]):\n",
    "        hyperparams_i = {x:y for x,y in zip(df_hyperparams.columns, df_hyperparams.loc[param_set_i].to_list())}\n",
    "        \n",
    "        # fix datatype for some vars\n",
    "        if 'max_depth' in hyperparams_i.keys():\n",
    "          hyperparams_i['max_depth'] = int(hyperparams_i['max_depth'])\n",
    "\n",
    "        # fit xgb\n",
    "        booster = xgb.train(\n",
    "          hyperparams_i,\n",
    "          dmat_train,\n",
    "          num_boost_round=100, \n",
    "          early_stopping_rounds=15,\n",
    "          evals = [(dmat_train, 'train'), (dmat_test, 'test')], \n",
    "          verbose_eval=False)\n",
    "        \n",
    "        # save results\n",
    "        rmse_train = get_rmse(dmat_train, df_train)\n",
    "        rmse_test = get_rmse(dmat_test, df_test)\n",
    "        final_res['fold'].append(fold_count)\n",
    "        final_res['hyperparams'].append(hyperparams_i)\n",
    "        final_res['rmse_train'].append(rmse_train)\n",
    "        final_res['rmse_test'].append(rmse_test)\n",
    "\n",
    "        if verbose == 2:\n",
    "          print('{}: rmse train: {:.3f}, rmse test: {:.3f}'.format(hyperparams_i, rmse_train, rmse_test))\n",
    "\n",
    "    elif search_type == 'random': \n",
    "      pass \n",
    "      # haven't done this yet\n",
    "  \n",
    "  # print out final best hyperparams before returning the output\n",
    "  output2 = pd.DataFrame({\n",
    "    'hyperparams': final_res['hyperparams'],\n",
    "    'fold': final_res['fold'],\n",
    "    'rmse_train': final_res['rmse_train'],\n",
    "    'rmse_test': final_res['rmse_test']\n",
    "  })\n",
    "  output2['hyperparams'] = output2['hyperparams'].astype(str)\n",
    "  output2 = output2.groupby('hyperparams')[['rmse_train', 'rmse_test']].mean().reset_index().sort_values('rmse_test')\n",
    "  print('best hyperparams: {}'.format(output2.iloc[0,0]))\n",
    "\n",
    "  \n",
    "  return final_res\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on fold 1/5\n",
      "Working on fold 2/5\n",
      "Working on fold 3/5\n",
      "Working on fold 4/5\n",
      "Working on fold 5/5\n",
      "best hyperparams: {'max_depth': 1, 'subsample': 1.0, 'eta': 0.3, 'lambda': 1.0}\n"
     ]
    }
   ],
   "source": [
    "output = time_series_cv(df, xvars = num_vars + counties + months, yvar = 'y_hematopoietic', \n",
    "  hyperparams = {'max_depth': [1, 5], 'subsample': [.8, 1], 'eta': [.1, .3], 'lambda': [1, .8]}, \n",
    "  search_type = 'grid', \n",
    "  folds = 5, \n",
    "  verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional\n",
    "\n",
    "Organize the results manually. But I put this in the function to spit the best result at the end anyways. \n",
    "\n",
    "But this shows how you can manipulate and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>fold</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>rmse_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 0.8, 'eta': 0.1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098889</td>\n",
       "      <td>0.131185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 1.0, 'eta': 0.1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096023</td>\n",
       "      <td>0.128173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 0.8, 'eta': 0.1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124585</td>\n",
       "      <td>0.174960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 1.0, 'eta': 0.1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148360</td>\n",
       "      <td>0.198804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 0.8, 'eta': 0.3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090540</td>\n",
       "      <td>0.122365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 1.0, 'eta': 0.1,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.255362</td>\n",
       "      <td>0.403228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 0.8, 'eta': 0.3,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.254656</td>\n",
       "      <td>0.389784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 1.0, 'eta': 0.3,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.254884</td>\n",
       "      <td>0.387370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 0.8, 'eta': 0.3,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.238637</td>\n",
       "      <td>0.399839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 1.0, 'eta': 0.3,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.240153</td>\n",
       "      <td>0.401812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          hyperparams  fold  rmse_train  \\\n",
       "0   {'max_depth': 1, 'subsample': 0.8, 'eta': 0.1,...     0    0.098889   \n",
       "1   {'max_depth': 1, 'subsample': 1.0, 'eta': 0.1,...     0    0.096023   \n",
       "2   {'max_depth': 5, 'subsample': 0.8, 'eta': 0.1,...     0    0.124585   \n",
       "3   {'max_depth': 5, 'subsample': 1.0, 'eta': 0.1,...     0    0.148360   \n",
       "4   {'max_depth': 1, 'subsample': 0.8, 'eta': 0.3,...     0    0.090540   \n",
       "..                                                ...   ...         ...   \n",
       "75  {'max_depth': 5, 'subsample': 1.0, 'eta': 0.1,...     4    0.255362   \n",
       "76  {'max_depth': 1, 'subsample': 0.8, 'eta': 0.3,...     4    0.254656   \n",
       "77  {'max_depth': 1, 'subsample': 1.0, 'eta': 0.3,...     4    0.254884   \n",
       "78  {'max_depth': 5, 'subsample': 0.8, 'eta': 0.3,...     4    0.238637   \n",
       "79  {'max_depth': 5, 'subsample': 1.0, 'eta': 0.3,...     4    0.240153   \n",
       "\n",
       "    rmse_test  \n",
       "0    0.131185  \n",
       "1    0.128173  \n",
       "2    0.174960  \n",
       "3    0.198804  \n",
       "4    0.122365  \n",
       "..        ...  \n",
       "75   0.403228  \n",
       "76   0.389784  \n",
       "77   0.387370  \n",
       "78   0.399839  \n",
       "79   0.401812  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2 = pd.DataFrame({\n",
    "  'hyperparams': output['hyperparams'],\n",
    "  'fold': output['fold'],\n",
    "  'rmse_train': output['rmse_train'],\n",
    "  'rmse_test': output['rmse_test']\n",
    "})\n",
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>rmse_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 0.8, 'eta': 0.1,...</td>\n",
       "      <td>0.185906</td>\n",
       "      <td>0.272150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 0.8, 'eta': 0.1,...</td>\n",
       "      <td>0.185906</td>\n",
       "      <td>0.272149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 0.8, 'eta': 0.3,...</td>\n",
       "      <td>0.168777</td>\n",
       "      <td>0.256342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 0.8, 'eta': 0.3,...</td>\n",
       "      <td>0.168776</td>\n",
       "      <td>0.256342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 1.0, 'eta': 0.1,...</td>\n",
       "      <td>0.185906</td>\n",
       "      <td>0.271774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 1.0, 'eta': 0.1,...</td>\n",
       "      <td>0.185906</td>\n",
       "      <td>0.271774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 1.0, 'eta': 0.3,...</td>\n",
       "      <td>0.169190</td>\n",
       "      <td>0.255671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 1, 'subsample': 1.0, 'eta': 0.3,...</td>\n",
       "      <td>0.169190</td>\n",
       "      <td>0.255670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 0.8, 'eta': 0.1,...</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>0.300596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 0.8, 'eta': 0.1,...</td>\n",
       "      <td>0.202083</td>\n",
       "      <td>0.300380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 0.8, 'eta': 0.3,...</td>\n",
       "      <td>0.151557</td>\n",
       "      <td>0.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 0.8, 'eta': 0.3,...</td>\n",
       "      <td>0.152497</td>\n",
       "      <td>0.267273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 1.0, 'eta': 0.1,...</td>\n",
       "      <td>0.197805</td>\n",
       "      <td>0.297465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 1.0, 'eta': 0.1,...</td>\n",
       "      <td>0.196764</td>\n",
       "      <td>0.296322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 1.0, 'eta': 0.3,...</td>\n",
       "      <td>0.154071</td>\n",
       "      <td>0.270412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 5, 'subsample': 1.0, 'eta': 0.3,...</td>\n",
       "      <td>0.154371</td>\n",
       "      <td>0.269291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          hyperparams  rmse_train  rmse_test\n",
       "0   {'max_depth': 1, 'subsample': 0.8, 'eta': 0.1,...    0.185906   0.272150\n",
       "1   {'max_depth': 1, 'subsample': 0.8, 'eta': 0.1,...    0.185906   0.272149\n",
       "2   {'max_depth': 1, 'subsample': 0.8, 'eta': 0.3,...    0.168777   0.256342\n",
       "3   {'max_depth': 1, 'subsample': 0.8, 'eta': 0.3,...    0.168776   0.256342\n",
       "4   {'max_depth': 1, 'subsample': 1.0, 'eta': 0.1,...    0.185906   0.271774\n",
       "5   {'max_depth': 1, 'subsample': 1.0, 'eta': 0.1,...    0.185906   0.271774\n",
       "6   {'max_depth': 1, 'subsample': 1.0, 'eta': 0.3,...    0.169190   0.255671\n",
       "7   {'max_depth': 1, 'subsample': 1.0, 'eta': 0.3,...    0.169190   0.255670\n",
       "8   {'max_depth': 5, 'subsample': 0.8, 'eta': 0.1,...    0.201704   0.300596\n",
       "9   {'max_depth': 5, 'subsample': 0.8, 'eta': 0.1,...    0.202083   0.300380\n",
       "10  {'max_depth': 5, 'subsample': 0.8, 'eta': 0.3,...    0.151557   0.267600\n",
       "11  {'max_depth': 5, 'subsample': 0.8, 'eta': 0.3,...    0.152497   0.267273\n",
       "12  {'max_depth': 5, 'subsample': 1.0, 'eta': 0.1,...    0.197805   0.297465\n",
       "13  {'max_depth': 5, 'subsample': 1.0, 'eta': 0.1,...    0.196764   0.296322\n",
       "14  {'max_depth': 5, 'subsample': 1.0, 'eta': 0.3,...    0.154071   0.270412\n",
       "15  {'max_depth': 5, 'subsample': 1.0, 'eta': 0.3,...    0.154371   0.269291"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2['hyperparams'] = output2['hyperparams'].astype(str)\n",
    "output_grp = output2.groupby('hyperparams')[['rmse_train', 'rmse_test']].mean().reset_index()\n",
    "output_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyperparams: {'max_depth': 1, 'subsample': 0.8, 'eta': 0.1, 'lambda': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print('best hyperparams: {}'.format(output_grp.iloc[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
