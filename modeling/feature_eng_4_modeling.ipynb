{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning our main dataset to use in modeling\n",
    "\n",
    "This script does the following:\n",
    "- Loads our main joined dataset and medical diagnoses data\n",
    "- Cleans the above datsets\n",
    "- Performs the following feature engineering:\n",
    "  - Compute rolling averages of prior pm2.5 levels\n",
    "  - One-hot encode categorical features: school_region, month\n",
    "  - Get year from date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional. I'm getting annoying warnings that I just want to ignore:\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# basics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "# modeling\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local or gdrive\n",
    "path_source = 'local'\n",
    "\n",
    "if path_source == 'gdrive':\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  data_path = '/content/gdrive/MyDrive/Classes/W210_capstone/W210_Capstone/Data'\n",
    "  #env_path = '/content/gdrive/MyDrive/.env'\n",
    "  \n",
    "elif path_source == 'local':\n",
    "  data_path = '/Users/tj/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/Data'\n",
    "  #env_path = '/content/gdrive/MyDrive/.env'\n",
    "\n",
    "elif path_source == 'work':\n",
    "  data_path = '/Users/trevorjohnson/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in full joined dataset:\n",
    "df = pd.read_parquet(os.path.join(data_path, 'joined_data/joined_open_schools_only_10-10-22.parquet'))\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# read cornelia med data\n",
    "df1 = pd.read_csv(os.path.join(data_path, 'medical/hematopoietic_cancers.csv')).iloc[:,1:]\n",
    "df2 = pd.read_csv(os.path.join(data_path, 'medical/pediatric_vasculitis.csv')).iloc[:,1:]\n",
    "df3 = pd.read_csv(os.path.join(data_path, 'medical/type_1_diabetes.csv')).iloc[:,1:]\n",
    "\n",
    "# temperature data\n",
    "df_schools_temp = pd.read_parquet(os.path.join(data_path, 'temperature/schools_temp_lookup.parquet'))\n",
    "df_ps_temp = pd.read_parquet(os.path.join(data_path, 'temperature/point_poll_sources_temp_lookup.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Medical Data\n",
    "\n",
    "Join the three medical files into 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patzip_year_month</th>\n",
       "      <th>hematopoietic_cancers</th>\n",
       "      <th>number_of_visits_hem_cancers</th>\n",
       "      <th>pediatric_vasculitis</th>\n",
       "      <th>number_of_visits_vasc</th>\n",
       "      <th>type_1_diabetes</th>\n",
       "      <th>number_of_visits_diab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94112-2011-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95616-2004-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94545-2013-7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patzip_year_month  hematopoietic_cancers  number_of_visits_hem_cancers  \\\n",
       "0      94112-2011-4                    1.0                          17.0   \n",
       "1     95616-2004-11                    1.0                          17.0   \n",
       "2      94545-2013-7                    1.0                          17.0   \n",
       "\n",
       "   pediatric_vasculitis  number_of_visits_vasc  type_1_diabetes  \\\n",
       "0                   NaN                    NaN              NaN   \n",
       "1                   NaN                    NaN              NaN   \n",
       "2                   NaN                    NaN              NaN   \n",
       "\n",
       "   number_of_visits_diab  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all distinct patzip_year_month\n",
    "all_pats = df1['patzip_year_month'].to_list() + df2['patzip_year_month'].to_list() + df3['patzip_year_month'].to_list()\n",
    "all_pats = list(set(all_pats))\n",
    "df_med = pd.DataFrame({'patzip_year_month': all_pats})\n",
    "\n",
    "# rename columns more intuitively\n",
    "df1 = df1.rename(columns={'number_of_visits': 'number_of_visits_hem_cancers'})\n",
    "df2 = df2.rename(columns={'number_of_visits': 'number_of_visits_vasc'})\n",
    "df3 = df3.rename(columns={'number_of_visits': 'number_of_visits_diab'})\n",
    "\n",
    "# now join all the diagnoses on this dataset\n",
    "df_med = df_med\\\n",
    "  .merge(df1, on='patzip_year_month', how='left')\\\n",
    "  .merge(df2, on='patzip_year_month', how='left')\\\n",
    "  .merge(df3, on='patzip_year_month', how='left')\n",
    "\n",
    "df_med.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'starting row count: {df.shape[0]}')\n",
    "\n",
    "# clean up column names. Make them all lower cased, and replace spaces with \"_\"\n",
    "df.columns = df.columns.str.replace(\"\\.*\\s+\", \"_\").str.lower()\n",
    "\n",
    "# fix some datatypes\n",
    "num_vars = ['angle_to_school', 'ps_elevation_m', 'pm25', 'point_source_pm25_tpy', \n",
    "            'dist_school_to_ps_m', 'angle_to_school', 'avg_wind_alignment_cosine',\n",
    "            'total_population', 'total_population_male', 'total_population_female', \n",
    "            'population_0_4', 'population_0_4_male', 'population_0_4_female',\n",
    "            'population_5_9', 'population_5_9_male', 'population_5_9_female',\n",
    "            'population_10_14', 'population_10_14_male', 'population_10_14_female',\n",
    "            'population_15_19', 'population_15_19_male', 'population_15_19_female',\n",
    "            'total_pop_under19', 'point_source_lat', 'point_source_lon']\n",
    "\n",
    "for var in num_vars:\n",
    "  df[var] = df[var].astype(float)\n",
    "\n",
    "# filter out na pm2.5 values (133,261 of them)\n",
    "df = df[~df['pm25'].isna()]\n",
    "\n",
    "# 1,584 records are missing population in the year 2000. B/c the 2000 data had less zip codes.\n",
    "# Filter them out since we aren't using 2000 anyways. \n",
    "df = df[~df['population_10_14'].isna()]\n",
    "\n",
    "# mean impute these vars\n",
    "mean_impute_vars = ['ca_agi_per_returns', 'total_tax_liability']\n",
    "for var in mean_impute_vars:\n",
    "  df[var] = df[var].fillna(df[var].mean())\n",
    "\n",
    "# 3 zips have 0 population, just filter those out\n",
    "df = df[df['total_population'] != 0]\n",
    "\n",
    "# get tax per capita (watch out for inf and nan)\n",
    "df['tax_liability_per_capita'] = df['total_tax_liability'] / df['total_population']\n",
    "\n",
    "print(f'ending row count: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of distinct year-mo-zips: 312009\n",
      "count of distinct for all join vars: 312009\n"
     ]
    }
   ],
   "source": [
    "# pre-grouping checks:\n",
    "n = df[['year_month', 'school_zip']].drop_duplicates().shape[0]\n",
    "print(f'count of distinct year-mo-zips: {n}')\n",
    "\n",
    "# including the population counts in this\n",
    "n = df[['year_month', 'school_zip', 'school_county_v2', 'school_region_name',\n",
    "  'pop_under19_male', 'pop_under19_female', 'total_pop_under19', 'pm25', \n",
    "  'ca_agi_per_returns', 'total_tax_liability']]\\\n",
    "  .drop_duplicates().shape[0]\n",
    "print(f'count of distinct for all join vars: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows of grouped df: 312009\n"
     ]
    }
   ],
   "source": [
    "# maybe not all of these should use 'mean', but doing it this way for now. \n",
    "mean_vars = ['school_wspd', 'school_elevation_m', 'ps_elevation_m', 'ps_elevation_m', 'point_source_pm25_tpy', \n",
    "  'dist_school_to_ps_m', 'angle_to_school', 'ps_wspd_merge', 'school_wdir_wrt_0n', 'ps_wdir_wrt_0n', \n",
    "  'school_wind_alignment', 'ps_wind_alignment', 'avg_wind_speed', 'avg_wind_alignment', 'avg_wind_alignment_cosine',\n",
    "  'nearby_point_source_count', 'ca_agi_per_returns', 'total_tax_liability', 'tax_liability_per_capita',\n",
    "\n",
    "  'population_0_4', 'population_0_4_male', 'population_0_4_female', \n",
    "  'population_5_9', 'population_5_9_male', 'population_5_9_female', \n",
    "  'population_10_14', 'population_10_14_male', 'population_10_14_female', \n",
    "  'population_15_19', 'population_15_19_male','population_15_19_female', \n",
    "  'total_pop_under19', 'pop_under19_male', 'pop_under19_female', \n",
    "  'total_population', 'total_population_male', 'total_population_female', \n",
    "  ]\n",
    "\n",
    "count_vars = ['cdscode']\n",
    "\n",
    "mean_dict = {var:(var, 'mean') for var in mean_vars}\n",
    "count_dict = {var:(var, 'count') for var in count_vars}\n",
    "agg_dict = {**mean_dict, **count_dict}\n",
    "\n",
    "grp_vars = ['year_month', 'school_zip', 'school_county_v2', 'school_region_name', 'pm25']\n",
    "\n",
    "df_grp = df\\\n",
    "  .groupby(grp_vars)\\\n",
    "  .agg(**agg_dict)\\\n",
    "  .reset_index()\n",
    "\n",
    "df_grp = df_grp.rename(columns = {'cdscode':'school_count'})\n",
    "\n",
    "print(f'Num rows of grouped df: {df_grp.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create rolling avg of pm2.5 (6, 9, and 12 month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df rolling avg\n",
    "df_avgs = df_grp[['year_month', 'school_zip', 'pm25']].sort_values(['school_zip', 'year_month'])\n",
    "\n",
    "# get rolling n month avg\n",
    "def create_rolling_avg(df, num_months=6):\n",
    "  df[f'pm25_r{num_months}'] = df.groupby('school_zip')['pm25']\\\n",
    "    .apply(lambda x: x.rolling(window=num_months, min_periods=num_months, closed='left').mean())\n",
    "    \n",
    "  return df \n",
    "\n",
    "\n",
    "df_avgs = create_rolling_avg(df_avgs, 6)\n",
    "df_avgs = create_rolling_avg(df_avgs, 9)\n",
    "df_avgs = create_rolling_avg(df_avgs, 12)\n",
    "df_avgs = create_rolling_avg(df_avgs, 24)\n",
    "\n",
    "# count num obs over past n months (don't need this, but keeping it commented just in case)\n",
    "# df_avgs['pm25_6mo_count'] = df_avgs.groupby('school_zip')['pm25'].apply(lambda x: x.rolling(6, 1, closed='left').apply(lambda x: len(x)))\n",
    "# df_avgs['pm25_9mo_count'] = df_avgs.groupby('school_zip')['pm25'].apply(lambda x: x.rolling(9, 1, closed='left').apply(lambda x: len(x)))\n",
    "# df_avgs['pm25_12mo_count'] = df_avgs.groupby('school_zip')['pm25'].apply(lambda x: x.rolling(12, 1, closed='left').apply(lambda x: len(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 schools have some time gaps. But only 5 of them. So not too much to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_days\n",
       "31 days      180622\n",
       "30 days      103992\n",
       "28 days       19193\n",
       "29 days        6809\n",
       "92 days           1\n",
       "458 days          1\n",
       "761 days          1\n",
       "762 days          1\n",
       "1188 days         1\n",
       "1553 days         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avgs['num_days'] = df_avgs.groupby('school_zip')['year_month'].apply(lambda x: x.diff())\n",
    "df_avgs.value_counts('num_days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the rolling averages back to main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't need:\n",
    "df_avgs = df_avgs.drop(columns=['pm25', 'num_days'])\n",
    "# join them\n",
    "df_grp = pd.merge(df_grp, df_avgs, on=['school_zip', 'year_month'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the med data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312009\n"
     ]
    }
   ],
   "source": [
    "df_grp['zip_year_month'] = df_grp['school_zip'].astype(str) + '-' +\\\n",
    "  df_grp['year_month'].dt.year.astype(str) + '-' +\\\n",
    "  df_grp['year_month'].dt.month.astype(str)\n",
    "\n",
    "df_grp = pd.merge(df_grp, df_med, left_on='zip_year_month', right_on='patzip_year_month', how='left')\n",
    "\n",
    "# for missing med data, assume there were 0 cases:\n",
    "med_vars = ['hematopoietic_cancers', 'number_of_visits_hem_cancers', 'pediatric_vasculitis', \n",
    "  'number_of_visits_vasc', 'type_1_diabetes', 'number_of_visits_diab']\n",
    "for var in med_vars:\n",
    "  df_grp[var] = df_grp[var].fillna(0)\n",
    "\n",
    "print(df_grp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp = df_grp.drop(columns = ['zip_year_month', 'patzip_year_month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode categorical features\n",
    "- School region\n",
    "- Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create year var\n",
    "df_grp['year'] = df_grp['year_month'].dt.year\n",
    "\n",
    "# create month. convert to string and make it two digits so we can one-hot encode\n",
    "df_grp['month'] = df_grp['year_month'].dt.month.map(lambda x: str(x).rjust(2, '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_cols = ['school_region_name', 'month']\n",
    "df_one_hot = pd.get_dummies(df_grp[['year_month', 'school_zip'] + encode_cols])\n",
    "df_one_hot.columns = df_one_hot.columns.str.replace(\"\\.*\\s+\", \"_\").str.lower()\n",
    "\n",
    "df_grp = pd.merge(df_grp.drop(columns=encode_cols), df_one_hot, on=['year_month', 'school_zip'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312009"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp.to_csv(os.path.join(data_path, 'modeling_data/modeling_data_2022-10-15.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('miniconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b25cd5a5a3cd1ea9e93fd254f185f4731ffaa4421de0b98534600687fe3ed44f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
