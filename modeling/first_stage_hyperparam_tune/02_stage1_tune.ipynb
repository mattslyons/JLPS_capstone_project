{"cells":[{"cell_type":"markdown","metadata":{"id":"CUPTOWCfNAqs"},"source":["# About\n","\n","Create a function that can be used in the 2nd stage regression to perform a time series cross validation. \n","- Using an expanding window cross validation\n","- Use sklearn API for the xgb function\n","\n","The 2nd stage regression predicts the medical outcomes using the predicted PM2.5 (and separately with the actual pm2.5), as well as the same fixed effects from the first stage regression. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZWKcsbcNAqw"},"outputs":[],"source":["# optional. I'm getting annoying warnings that I just want to ignore:\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","# basics\n","import pandas as pd \n","import numpy as np\n","import os \n","import re\n","from datetime import datetime\n","from tqdm.notebook import tqdm\n","tqdm.pandas()\n","import requests\n","import urllib\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n","from sklearn.model_selection import TimeSeriesSplit\n","\n","# plotting\n","import matplotlib.pyplot as plt\n","from matplotlib.dates import DateFormatter\n","import plotly.express as px\n","import seaborn as sns\n","\n","# modeling\n","from patsy import dmatrices\n","import statsmodels.api as sm\n","from sklearn.linear_model import LinearRegression\n","from statsmodels.sandbox.regression.gmm import IV2SLS\n","import xgboost as xgb\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","\n","pd.set_option('display.max_columns', None)\n","pd.options.mode.chained_assignment = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K90Hj01sNAqx"},"outputs":[],"source":["# keep this as false unless you want to save out the fitted model objects and results \n","save_results = False"]},{"cell_type":"markdown","metadata":{"id":"QI9QbmOtNAqx"},"source":["Set lag/lead times"]},{"cell_type":"markdown","metadata":{"id":"00sYaQ_jNAqx"},"source":["Combinations of Instruments and Fixed Effects here:\n","https://docs.google.com/spreadsheets/d/1_MMYeQuxiov2OLE5AX0CE9R1T1mBrk7vpozy2fGjNBg/edit#gid=0 \n","\n","Instruments:\n","\n","- `Izmy_v3_normed_D_and_TPY`\n","- `Izmy_v4_nodist_normed_TPY`\n","- `Izmy_v5_all_normed_but_wspd_ratio`\n","\n","\n","We will use lead and lag of 9 months and 3 months respectively.\n","\n","For fixed effects, we choose from a set of 4 possible combinations outlined here:\n","\n","- https://docs.google.com/spreadsheets/d/1_MMYeQuxiov2OLE5AX0CE9R1T1mBrk7vpozy2fGjNBg/edit#gid=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c85trRQzNAqy"},"outputs":[],"source":["# set instrumental variable version\n","##  Predictor options:\n","# - `Izmy_v3_normed_D_and_TPY`\n","# - `Izmy_v4_nodist_normed_TPY`\n","# - `Izmy_v5_all_normed_but_wspd_ratio`\n","\n","predictor = 'Izmy_v3_normed_D_and_TPY'\n","\n","# set FE to one of 4 sets (int)\n","FE_set_num = 2\n","\n","# sets unique notebooks index (string)\n","notebook_index = \"02\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EElVdw8rNAqy","executionInfo":{"status":"ok","timestamp":1669605515784,"user_tz":420,"elapsed":3,"user":{"displayName":"Trevor Johnson","userId":"10875792761423186902"}},"outputId":"fa02a4e0-f727-4116-f280-5b7317b0327e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Stage 1\n","Target Name (target_name_s1) = pm25_r9\n","Predictor Name (predictor_name_s1) = Izmy_v3_normed_D_and_TPY_r9\n","\n","Stage 2\n","Health Outcome Lag Input (HO_lag_input) = _fwd3\n"]}],"source":["lead_time = '9'\n","lag_time = '3'\n","lag_style = 'fwd'\n","\n","# define lead time for IV: 'last_month', 'r6', 'r9', 'r12'\n","IV_lead = \"r\" + str(lead_time)\n","HO_lag = lag_style + str(lag_time)\n","\n","if IV_lead:\n","    IV_lead_input = \"_\" + IV_lead \n","else:\n","    # don't add underscore if empty string\n","    IV_lead_input = IV_lead\n","\n","# define lag time for Health Outcome: '', 'fwd3', 'cent3', 'fwd6', 'cent6', 'fwd12', 'cent12'\n","if HO_lag:\n","    HO_lag_input = \"_\" + HO_lag \n","else:\n","    # don't add underscore if empty string\n","    HO_lag_input = HO_lag\n","\n","# IV options: 1 month, 6 months, 9 months, 12 months\n","IV_window_col = [f'pm25{IV_lead_input}']\n","\n","# health outcome options (fwd or cent): 1 month, 3 months, 6 months, 12 months\n","health_outcome_window_col = [f'y_injuries{HO_lag_input}']\n","\n","filter_cols = IV_window_col + health_outcome_window_col # columns to filter out at the beginning and end of df, before modeling\n","\n","target_name_s1 = f'pm25{IV_lead_input}'\n","predictor_name_s1 = f'{predictor}{IV_lead_input}'\n","\n","print(f\"Stage 1\\nTarget Name (target_name_s1) = {target_name_s1}\\nPredictor Name (predictor_name_s1) = {predictor_name_s1}\")\n","\n","print(f\"\\nStage 2\\nHealth Outcome Lag Input (HO_lag_input) = {HO_lag_input}\")"]},{"cell_type":"markdown","metadata":{"id":"NbnjdzzCNAqz"},"source":["# Set Path\n","\n","Add a new elif section for your path if you want"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UEVu8Vq1NAqz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669605610690,"user_tz":420,"elapsed":18487,"user":{"displayName":"Trevor Johnson","userId":"10875792761423186902"}},"outputId":"68010aba-7ecb-4d8e-ed9b-8c15dd9b35d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# add a section to the elif statement for your personal paths\n","# make sure it points \"data\" folder that we share \n","path_source = 'gdrive_tj'\n","\n","if path_source == 'gdrive':\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","  data_path = '/content/gdrive/MyDrive/Classes/W210_capstone/W210_Capstone/Data'\n","  fitted_models_path = '/content/gdrive/MyDrive/Classes/W210_capstone/W210_Capstone/fitted_models/2022-10-23'\n","\n","elif path_source == 'gdrive_tj':\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","  data_path = '/content/gdrive/MyDrive/w210/W210_Capstone/Data'\n","  fitted_models_path = '/content/gdrive/MyDrive/w210/W210_Capstone/fitted_models/2022-11-27'\n","\n","elif path_source == 'local':\n","  data_path = '/Users/tj/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/Data'\n","  fitted_models_path = '/Users/tj/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/fitted_models/2022-10-23'\n","\n","elif path_source == 'local_anand':\n","  data_path = 'G:\\\\.shortcut-targets-by-id\\\\11wLy1WKwOTcthBs1rpfEzkqax2BZG-6E\\\\W210_Capstone\\\\Data'\n","  fitted_models_path = 'G:\\\\.shortcut-targets-by-id\\\\11wLy1WKwOTcthBs1rpfEzkqax2BZG-6E\\W210_Capstone\\\\fitted_models\\\\2022-11-19\\\\XGB'\n","\n","  out_dir1 = 'G:\\\\.shortcut-targets-by-id\\\\11wLy1WKwOTcthBs1rpfEzkqax2BZG-6E\\W210_Capstone\\\\fitted_models\\\\2022-11-19\\\\XGB'\n","\n","elif path_source == 'local_cornelia':\n","  in_dir_sc = 'C:/Users/cilin/Research/CA_hospitals_capstone/data/'\n","  in_dir_h = 'C:/Users/cilin/Research/CA_hospitals_capstone/output/'\n","  # folder containing stage 1 outputs\n","  out_dir1 = 'C:/Users/cilin/Research/CA_hospitals_capstone/models_s1/'\n","  # folder containing stage 2 outputs\n","  out_dir2 = 'C:/Users/cilin/Research/CA_hospitals_capstone/models_s2/'\n","  # folder containing csvs documenting which fixed effects are in which csv files\n","  out_dir3 = 'C:/Users/cilin/Research/CA_hospitals_capstone/fixed_effects/'\n","\n","elif path_source == 'work':\n","  data_path = '/Users/trevorjohnson/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/Data'\n","  fitted_models_path = '/Users/trevorjohnson/trevorj@berkeley.edu - Google Drive/My Drive/Classes/W210_capstone/W210_Capstone/fitted_models/2022-10-23'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeDDINA7NAq0"},"outputs":[],"source":["# read in our modeling data\n","df = pd.read_csv(os.path.join(data_path, 'modeling_data/modeling_data_joined_11-22-top15_4tpy_ds_wind_ratios.csv'))\n","\n","# read in cornelia's healthcare data\n","df1 = pd.read_csv(os.path.join(data_path, 'medical/hematopoietic_cancers.csv')).iloc[:,1:]\n","df2 = pd.read_csv(os.path.join(data_path, 'medical/pediatric_vasculitis.csv')).iloc[:,1:]\n","df3 = pd.read_csv(os.path.join(data_path, 'medical/type_1_diabetes.csv')).iloc[:,1:]\n","df4 = pd.read_csv(os.path.join(data_path, 'medical/resp_cardio.csv')).iloc[:,1:]\n","df5 = pd.read_csv(os.path.join(data_path, 'medical/injuries_accidents.csv')).iloc[:,1:]"]},{"cell_type":"markdown","metadata":{"id":"yp7Wv5ESNAq0"},"source":["# Data Clean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WoBLkqKgNAq0","outputId":"42d615cb-4ea2-44c0-efc0-112da5534216","colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"status":"ok","timestamp":1669605654933,"user_tz":420,"elapsed":7527,"user":{"displayName":"Trevor Johnson","userId":"10875792761423186902"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of data  (311163, 165)\n"]},{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  Unnamed: 0.1  year_month  school_zip school_county_v2  \\\n","0           0             0  2000-01-01       90001      Los Angeles   \n","1        1322          1322  2000-02-01       90001      Los Angeles   \n","\n","   school_region_name       pm25  school_elevation_m  ps_elevation_m  \\\n","0  Los Angeles County  32.149998           44.728889       43.703333   \n","1  Los Angeles County  13.666667           44.728889       43.703333   \n","\n","   population_0_4  population_0_4_male  population_0_4_female  population_5_9  \\\n","0          6196.0               3209.0                 2987.0          6672.0   \n","1          6196.0               3209.0                 2987.0          6672.0   \n","\n","   population_5_9_male  population_5_9_female  population_10_14  \\\n","0               3397.0                 3275.0            5562.0   \n","1               3397.0                 3275.0            5562.0   \n","\n","   population_10_14_male  population_10_14_female  population_15_19  \\\n","0                 2850.0                   2712.0            5075.0   \n","1                 2850.0                   2712.0            5075.0   \n","\n","   population_15_19_male  population_15_19_female  total_pop_under19  \\\n","0                 2599.0                   2476.0            23505.0   \n","1                 2599.0                   2476.0            23505.0   \n","\n","   pop_under19_male  pop_under19_female  total_population  \\\n","0           12055.0             11450.0           54481.0   \n","1           12055.0             11450.0           54481.0   \n","\n","   total_population_male  total_population_female  point_source_pm25_tpy  \\\n","0                27320.0                  27161.0              14.241154   \n","1                27320.0                  27161.0              14.241154   \n","\n","   dist_school_to_ps_m  angle_to_school  ps_wspd_merge  school_wdir_wrt_0n  \\\n","0          3854.812685       -90.196586       0.757031         -172.758321   \n","1          3854.812685       -90.196586       0.965276           30.294778   \n","\n","   ps_wdir_wrt_0n  school_wind_alignment  ps_wind_alignment  \\\n","0     -172.758321              82.561735          82.561735   \n","1       30.294778             120.491364         120.491364   \n","\n","   avg_wind_alignment  avg_wind_alignment_cosine  nearby_point_source_count  \\\n","0           82.561735                   1.124995                        0.0   \n","1          120.491364                   0.547186                        0.0   \n","\n","   school_wspd  ca_agi_per_returns  total_tax_liability  \\\n","0     0.757031        20049.704556            2608176.0   \n","1     0.965276        20049.704556            2608176.0   \n","\n","   tax_liability_per_capita  school_temperature  ps_temperature  school_count  \\\n","0                  47.87313           14.277778       14.266667             9   \n","1                  47.87313           13.877778       13.866667             9   \n","\n","     pm25_r1  pm25_r6  pm25_r9  pm25_r12  pm25_r24  pm25_slope6  pm25_slope9  \\\n","0        NaN      NaN      NaN       NaN       NaN          NaN          NaN   \n","1  32.149998      NaN      NaN       NaN       NaN          NaN          NaN   \n","\n","   pm25_slope12  pm25_slope24  pm25_lag_12mo  year  month  \\\n","0           NaN           NaN            NaN  2000      1   \n","1           NaN           NaN            NaN  2000      2   \n","\n","   school_county_v2_alameda  school_county_v2_alpine  school_county_v2_amador  \\\n","0                         0                        0                        0   \n","1                         0                        0                        0   \n","\n","   school_county_v2_butte  school_county_v2_calaveras  \\\n","0                       0                           0   \n","1                       0                           0   \n","\n","   school_county_v2_colusa  school_county_v2_contra_costa  \\\n","0                        0                              0   \n","1                        0                              0   \n","\n","   school_county_v2_del_norte  school_county_v2_el_dorado  \\\n","0                           0                           0   \n","1                           0                           0   \n","\n","   school_county_v2_fresno  school_county_v2_glenn  school_county_v2_humboldt  \\\n","0                        0                       0                          0   \n","1                        0                       0                          0   \n","\n","   school_county_v2_imperial  school_county_v2_inyo  school_county_v2_kern  \\\n","0                          0                      0                      0   \n","1                          0                      0                      0   \n","\n","   school_county_v2_kings  school_county_v2_lake  school_county_v2_lassen  \\\n","0                       0                      0                        0   \n","1                       0                      0                        0   \n","\n","   school_county_v2_los_angeles  school_county_v2_madera  \\\n","0                             1                        0   \n","1                             1                        0   \n","\n","   school_county_v2_marin  school_county_v2_mariposa  \\\n","0                       0                          0   \n","1                       0                          0   \n","\n","   school_county_v2_mendocino  school_county_v2_merced  \\\n","0                           0                        0   \n","1                           0                        0   \n","\n","   school_county_v2_modoc  school_county_v2_mono  school_county_v2_monterey  \\\n","0                       0                      0                          0   \n","1                       0                      0                          0   \n","\n","   school_county_v2_napa  school_county_v2_nevada  school_county_v2_orange  \\\n","0                      0                        0                        0   \n","1                      0                        0                        0   \n","\n","   school_county_v2_placer  school_county_v2_plumas  \\\n","0                        0                        0   \n","1                        0                        0   \n","\n","   school_county_v2_riverside  school_county_v2_sacramento  \\\n","0                           0                            0   \n","1                           0                            0   \n","\n","   school_county_v2_san_benito  school_county_v2_san_bernardino  \\\n","0                            0                                0   \n","1                            0                                0   \n","\n","   school_county_v2_san_diego  school_county_v2_san_francisco  \\\n","0                           0                               0   \n","1                           0                               0   \n","\n","   school_county_v2_san_joaquin  school_county_v2_san_luis_obispo  \\\n","0                             0                                 0   \n","1                             0                                 0   \n","\n","   school_county_v2_san_mateo  school_county_v2_santa_barbara  \\\n","0                           0                               0   \n","1                           0                               0   \n","\n","   school_county_v2_santa_clara  school_county_v2_santa_cruz  \\\n","0                             0                            0   \n","1                             0                            0   \n","\n","   school_county_v2_shasta  school_county_v2_sierra  \\\n","0                        0                        0   \n","1                        0                        0   \n","\n","   school_county_v2_siskiyou  school_county_v2_solano  \\\n","0                          0                        0   \n","1                          0                        0   \n","\n","   school_county_v2_sonoma  school_county_v2_stanislaus  \\\n","0                        0                            0   \n","1                        0                            0   \n","\n","   school_county_v2_sutter  school_county_v2_tehama  school_county_v2_trinity  \\\n","0                        0                        0                         0   \n","1                        0                        0                         0   \n","\n","   school_county_v2_tulare  school_county_v2_tuolumne  \\\n","0                        0                          0   \n","1                        0                          0   \n","\n","   school_county_v2_ventura  school_county_v2_yolo  school_county_v2_yuba  \\\n","0                         0                      0                      0   \n","1                         0                      0                      0   \n","\n","   month_01  month_02  month_03  month_04  month_05  month_06  month_07  \\\n","0         1         0         0         0         0         0         0   \n","1         0         1         0         0         0         0         0   \n","\n","   month_08  month_09  month_10  month_11  month_12      y-m  \\\n","0         0         0         0         0         0  2000-01   \n","1         0         0         0         0         0  2000-02   \n","\n","   central_wind_alignment_180_high  avg_count_ps_within_5km  \\\n","0                              NaN                      NaN   \n","1                              NaN                      NaN   \n","\n","   avg_elevation_diff_m  avg_wspd_ratio_ps_sch  avg_wspd_ratio_sch_ps  \\\n","0                   NaN                    NaN                    NaN   \n","1                   NaN                    NaN                    NaN   \n","\n","   avg_school_wspd  avg_ps_wspd  new_alignment_90_high  ps_pm25_tpy_top_20  \\\n","0              NaN          NaN                    NaN                 NaN   \n","1              NaN          NaN                    NaN                 NaN   \n","\n","   school_to_ps_geod_dist_m_top_20  avg_wspd_top_15  Izmy_v1_unnormed  \\\n","0                              NaN              NaN               NaN   \n","1                              NaN              NaN               NaN   \n","\n","   Izmy_v2_nodist_unnormed  Izmy_v3_normed_D_and_TPY  \\\n","0                      NaN                       NaN   \n","1                      NaN                       NaN   \n","\n","   Izmy_v4_nodist_normed_TPY  Izmy_v5_all_normed_but_wspd_ratio  \\\n","0                        NaN                                NaN   \n","1                        NaN                                NaN   \n","\n","   Izmy_v6_unnormed_no_wspd  Izmy_v7_all_normed_no_wspd  \\\n","0                       NaN                         NaN   \n","1                       NaN                         NaN   \n","\n","   Izmy_v8_normed_D_and_TPY_no_wspd   avg_temp  diff_temp_s_ps  \\\n","0                               NaN  14.272222        0.011111   \n","1                               NaN  13.872222        0.011111   \n","\n","   Izmy_v3_normed_D_and_TPY_r1  Izmy_v3_normed_D_and_TPY_r6  \\\n","0                          NaN                          NaN   \n","1                          NaN                          NaN   \n","\n","   Izmy_v3_normed_D_and_TPY_r9  Izmy_v3_normed_D_and_TPY_r12  \\\n","0                          NaN                           NaN   \n","1                          NaN                           NaN   \n","\n","   avg_wspd_top_15_r1  avg_wspd_top_15_r6  avg_wspd_top_15_r9  \\\n","0                 NaN                 NaN                 NaN   \n","1                 NaN                 NaN                 NaN   \n","\n","   avg_wspd_top_15_r12  avg_temp_r1  avg_temp_r6  avg_temp_r9  avg_temp_r12  \\\n","0                  NaN          NaN          NaN          NaN           NaN   \n","1                  NaN    14.272222          NaN          NaN           NaN   \n","\n","   diff_temp_s_ps_r1  diff_temp_s_ps_r6  diff_temp_s_ps_r9  diff_temp_s_ps_r12  \n","0                NaN                NaN                NaN                 NaN  \n","1           0.011111                NaN                NaN                 NaN  "],"text/html":["\n","  <div id=\"df-ea7c5248-04c7-475a-a32d-f3b422324616\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Unnamed: 0.1</th>\n","      <th>year_month</th>\n","      <th>school_zip</th>\n","      <th>school_county_v2</th>\n","      <th>school_region_name</th>\n","      <th>pm25</th>\n","      <th>school_elevation_m</th>\n","      <th>ps_elevation_m</th>\n","      <th>population_0_4</th>\n","      <th>population_0_4_male</th>\n","      <th>population_0_4_female</th>\n","      <th>population_5_9</th>\n","      <th>population_5_9_male</th>\n","      <th>population_5_9_female</th>\n","      <th>population_10_14</th>\n","      <th>population_10_14_male</th>\n","      <th>population_10_14_female</th>\n","      <th>population_15_19</th>\n","      <th>population_15_19_male</th>\n","      <th>population_15_19_female</th>\n","      <th>total_pop_under19</th>\n","      <th>pop_under19_male</th>\n","      <th>pop_under19_female</th>\n","      <th>total_population</th>\n","      <th>total_population_male</th>\n","      <th>total_population_female</th>\n","      <th>point_source_pm25_tpy</th>\n","      <th>dist_school_to_ps_m</th>\n","      <th>angle_to_school</th>\n","      <th>ps_wspd_merge</th>\n","      <th>school_wdir_wrt_0n</th>\n","      <th>ps_wdir_wrt_0n</th>\n","      <th>school_wind_alignment</th>\n","      <th>ps_wind_alignment</th>\n","      <th>avg_wind_alignment</th>\n","      <th>avg_wind_alignment_cosine</th>\n","      <th>nearby_point_source_count</th>\n","      <th>school_wspd</th>\n","      <th>ca_agi_per_returns</th>\n","      <th>total_tax_liability</th>\n","      <th>tax_liability_per_capita</th>\n","      <th>school_temperature</th>\n","      <th>ps_temperature</th>\n","      <th>school_count</th>\n","      <th>pm25_r1</th>\n","      <th>pm25_r6</th>\n","      <th>pm25_r9</th>\n","      <th>pm25_r12</th>\n","      <th>pm25_r24</th>\n","      <th>pm25_slope6</th>\n","      <th>pm25_slope9</th>\n","      <th>pm25_slope12</th>\n","      <th>pm25_slope24</th>\n","      <th>pm25_lag_12mo</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>school_county_v2_alameda</th>\n","      <th>school_county_v2_alpine</th>\n","      <th>school_county_v2_amador</th>\n","      <th>school_county_v2_butte</th>\n","      <th>school_county_v2_calaveras</th>\n","      <th>school_county_v2_colusa</th>\n","      <th>school_county_v2_contra_costa</th>\n","      <th>school_county_v2_del_norte</th>\n","      <th>school_county_v2_el_dorado</th>\n","      <th>school_county_v2_fresno</th>\n","      <th>school_county_v2_glenn</th>\n","      <th>school_county_v2_humboldt</th>\n","      <th>school_county_v2_imperial</th>\n","      <th>school_county_v2_inyo</th>\n","      <th>school_county_v2_kern</th>\n","      <th>school_county_v2_kings</th>\n","      <th>school_county_v2_lake</th>\n","      <th>school_county_v2_lassen</th>\n","      <th>school_county_v2_los_angeles</th>\n","      <th>school_county_v2_madera</th>\n","      <th>school_county_v2_marin</th>\n","      <th>school_county_v2_mariposa</th>\n","      <th>school_county_v2_mendocino</th>\n","      <th>school_county_v2_merced</th>\n","      <th>school_county_v2_modoc</th>\n","      <th>school_county_v2_mono</th>\n","      <th>school_county_v2_monterey</th>\n","      <th>school_county_v2_napa</th>\n","      <th>school_county_v2_nevada</th>\n","      <th>school_county_v2_orange</th>\n","      <th>school_county_v2_placer</th>\n","      <th>school_county_v2_plumas</th>\n","      <th>school_county_v2_riverside</th>\n","      <th>school_county_v2_sacramento</th>\n","      <th>school_county_v2_san_benito</th>\n","      <th>school_county_v2_san_bernardino</th>\n","      <th>school_county_v2_san_diego</th>\n","      <th>school_county_v2_san_francisco</th>\n","      <th>school_county_v2_san_joaquin</th>\n","      <th>school_county_v2_san_luis_obispo</th>\n","      <th>school_county_v2_san_mateo</th>\n","      <th>school_county_v2_santa_barbara</th>\n","      <th>school_county_v2_santa_clara</th>\n","      <th>school_county_v2_santa_cruz</th>\n","      <th>school_county_v2_shasta</th>\n","      <th>school_county_v2_sierra</th>\n","      <th>school_county_v2_siskiyou</th>\n","      <th>school_county_v2_solano</th>\n","      <th>school_county_v2_sonoma</th>\n","      <th>school_county_v2_stanislaus</th>\n","      <th>school_county_v2_sutter</th>\n","      <th>school_county_v2_tehama</th>\n","      <th>school_county_v2_trinity</th>\n","      <th>school_county_v2_tulare</th>\n","      <th>school_county_v2_tuolumne</th>\n","      <th>school_county_v2_ventura</th>\n","      <th>school_county_v2_yolo</th>\n","      <th>school_county_v2_yuba</th>\n","      <th>month_01</th>\n","      <th>month_02</th>\n","      <th>month_03</th>\n","      <th>month_04</th>\n","      <th>month_05</th>\n","      <th>month_06</th>\n","      <th>month_07</th>\n","      <th>month_08</th>\n","      <th>month_09</th>\n","      <th>month_10</th>\n","      <th>month_11</th>\n","      <th>month_12</th>\n","      <th>y-m</th>\n","      <th>central_wind_alignment_180_high</th>\n","      <th>avg_count_ps_within_5km</th>\n","      <th>avg_elevation_diff_m</th>\n","      <th>avg_wspd_ratio_ps_sch</th>\n","      <th>avg_wspd_ratio_sch_ps</th>\n","      <th>avg_school_wspd</th>\n","      <th>avg_ps_wspd</th>\n","      <th>new_alignment_90_high</th>\n","      <th>ps_pm25_tpy_top_20</th>\n","      <th>school_to_ps_geod_dist_m_top_20</th>\n","      <th>avg_wspd_top_15</th>\n","      <th>Izmy_v1_unnormed</th>\n","      <th>Izmy_v2_nodist_unnormed</th>\n","      <th>Izmy_v3_normed_D_and_TPY</th>\n","      <th>Izmy_v4_nodist_normed_TPY</th>\n","      <th>Izmy_v5_all_normed_but_wspd_ratio</th>\n","      <th>Izmy_v6_unnormed_no_wspd</th>\n","      <th>Izmy_v7_all_normed_no_wspd</th>\n","      <th>Izmy_v8_normed_D_and_TPY_no_wspd</th>\n","      <th>avg_temp</th>\n","      <th>diff_temp_s_ps</th>\n","      <th>Izmy_v3_normed_D_and_TPY_r1</th>\n","      <th>Izmy_v3_normed_D_and_TPY_r6</th>\n","      <th>Izmy_v3_normed_D_and_TPY_r9</th>\n","      <th>Izmy_v3_normed_D_and_TPY_r12</th>\n","      <th>avg_wspd_top_15_r1</th>\n","      <th>avg_wspd_top_15_r6</th>\n","      <th>avg_wspd_top_15_r9</th>\n","      <th>avg_wspd_top_15_r12</th>\n","      <th>avg_temp_r1</th>\n","      <th>avg_temp_r6</th>\n","      <th>avg_temp_r9</th>\n","      <th>avg_temp_r12</th>\n","      <th>diff_temp_s_ps_r1</th>\n","      <th>diff_temp_s_ps_r6</th>\n","      <th>diff_temp_s_ps_r9</th>\n","      <th>diff_temp_s_ps_r12</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2000-01-01</td>\n","      <td>90001</td>\n","      <td>Los Angeles</td>\n","      <td>Los Angeles County</td>\n","      <td>32.149998</td>\n","      <td>44.728889</td>\n","      <td>43.703333</td>\n","      <td>6196.0</td>\n","      <td>3209.0</td>\n","      <td>2987.0</td>\n","      <td>6672.0</td>\n","      <td>3397.0</td>\n","      <td>3275.0</td>\n","      <td>5562.0</td>\n","      <td>2850.0</td>\n","      <td>2712.0</td>\n","      <td>5075.0</td>\n","      <td>2599.0</td>\n","      <td>2476.0</td>\n","      <td>23505.0</td>\n","      <td>12055.0</td>\n","      <td>11450.0</td>\n","      <td>54481.0</td>\n","      <td>27320.0</td>\n","      <td>27161.0</td>\n","      <td>14.241154</td>\n","      <td>3854.812685</td>\n","      <td>-90.196586</td>\n","      <td>0.757031</td>\n","      <td>-172.758321</td>\n","      <td>-172.758321</td>\n","      <td>82.561735</td>\n","      <td>82.561735</td>\n","      <td>82.561735</td>\n","      <td>1.124995</td>\n","      <td>0.0</td>\n","      <td>0.757031</td>\n","      <td>20049.704556</td>\n","      <td>2608176.0</td>\n","      <td>47.87313</td>\n","      <td>14.277778</td>\n","      <td>14.266667</td>\n","      <td>9</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2000-01</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>14.272222</td>\n","      <td>0.011111</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1322</td>\n","      <td>1322</td>\n","      <td>2000-02-01</td>\n","      <td>90001</td>\n","      <td>Los Angeles</td>\n","      <td>Los Angeles County</td>\n","      <td>13.666667</td>\n","      <td>44.728889</td>\n","      <td>43.703333</td>\n","      <td>6196.0</td>\n","      <td>3209.0</td>\n","      <td>2987.0</td>\n","      <td>6672.0</td>\n","      <td>3397.0</td>\n","      <td>3275.0</td>\n","      <td>5562.0</td>\n","      <td>2850.0</td>\n","      <td>2712.0</td>\n","      <td>5075.0</td>\n","      <td>2599.0</td>\n","      <td>2476.0</td>\n","      <td>23505.0</td>\n","      <td>12055.0</td>\n","      <td>11450.0</td>\n","      <td>54481.0</td>\n","      <td>27320.0</td>\n","      <td>27161.0</td>\n","      <td>14.241154</td>\n","      <td>3854.812685</td>\n","      <td>-90.196586</td>\n","      <td>0.965276</td>\n","      <td>30.294778</td>\n","      <td>30.294778</td>\n","      <td>120.491364</td>\n","      <td>120.491364</td>\n","      <td>120.491364</td>\n","      <td>0.547186</td>\n","      <td>0.0</td>\n","      <td>0.965276</td>\n","      <td>20049.704556</td>\n","      <td>2608176.0</td>\n","      <td>47.87313</td>\n","      <td>13.877778</td>\n","      <td>13.866667</td>\n","      <td>9</td>\n","      <td>32.149998</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2000</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2000-02</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13.872222</td>\n","      <td>0.011111</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>14.272222</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.011111</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea7c5248-04c7-475a-a32d-f3b422324616')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ea7c5248-04c7-475a-a32d-f3b422324616 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ea7c5248-04c7-475a-a32d-f3b422324616');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["def roll_selected_cols(df, cols_to_roll:list = ['Izmy_v1_unnormed'\\\n","    ,'Izmy_v2_nodist_unnormed' \\\n","    ,'Izmy_v3_normed_D_and_TPY' \\\n","    ,'Izmy_v4_nodist_normed_TPY' \\\n","    ,'Izmy_v5_all_normed'\n","    ,'Izmy_v6_unnormed_no_wspd'\n","    ,'Izmy_v7_all_normed_no_wspd'\n","    ,'Izmy_v8_normed_D_and_TPY_no_wspd'\n","    ,'new_alignment_90_high'\n","    ,'avg_temp']\n","    ,rolling_periods:list = [1, 6, 9, 12]):\n","\n","    \"\"\"Generates rolling averages for the input variables over the input time periods.\n","    Inputs: df (pd dataframe): contains the data on a y-m level\n","            cols_to_roll (list): list of columns to generate rolling avgs--must be in df\n","            rolling_periods (list): list of time windows (in months) to roll over\n","            \n","    Outputs: df: Pandas dataframe containing the new columns\n","             all_cols: list of list containing the new columns, separated by input type\"\"\"\n","    \n","    df_int = df.copy().sort_values(['school_zip', 'year_month']).reset_index(drop=True)\n","    \n","    all_cols_int = []\n","\n","    # Roll each variable\n","    for col_index in range(len(cols_to_roll)):\n","        new_cols = []\n","\n","        col_to_roll = cols_to_roll[col_index]\n","        rolling_periods = [1, 6, 9, 12]\n","\n","        for period in rolling_periods:\n","            df_int[f'{col_to_roll}_r{period}'] = df_int.groupby('school_zip')[col_to_roll]\\\n","                .apply(lambda x: x.rolling(window=period, min_periods=period, closed='left').mean())\n","            \n","            new_cols.append(col_to_roll + \"_r\" + str(period))\n","\n","        all_cols_int.append([col_to_roll] + new_cols)\n","        \n","    return df_int, all_cols_int\n","\n","\n","cols_to_roll = [predictor\n","    ,'avg_wspd_top_15'\n","    ,'avg_temp'\n","    ,'diff_temp_s_ps']\n","\n","rolling_periods = [int(lead_time)]\n","\n","df, all_cols = roll_selected_cols(df=df, cols_to_roll=cols_to_roll, rolling_periods=rolling_periods)\n","\n","# rename the last month column just to be consistent and safe\n","df.rename(columns={'pm25_last_month': 'pm25_r1'}, inplace=True)\n","\n","# print shape of data\n","print('Shape of data ', df.shape)\n","df.head(2)"]},{"cell_type":"markdown","metadata":{"id":"bj6zupToNAq0"},"source":["#### Fill in nulls conditionally on merged datasets\n","\n","- the problem: for each health outcome, we want to fill in the nulls for a zipcode with 0's only if that row occurred after the first non-zero/not null visit in that zipcode for that health outcome. Keep them as nulls otherwise.\n","\n","- So basically a zipcode will keep the nulls if they're on a date before the first visit seen for that health outcome, nulls will become 0 after the first visit seen for that health outcome."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BmT6DL5NAq1"},"outputs":[],"source":["def filter_nans(df, visits_cols = ['visits_hematopoietic_cancers', 'visits_injuries_accidents',\n","       'visits_type_1_diabetes', 'visits_pediatric_vasculitis',\n","       'visits_resp_cardio']):\n","    \"\"\"Function to generate columns in place that replace NaNs with 0's only if that \n","    row occurred after the first non-zero/not null visit in that zipcode for the specific\n","    health outcome. Keeps them as nulls otherwise.\n","\n","    Args:\n","        df (DataFrame): Input dataframe\n","        visits_cols (list, optional): list of columns to selectively filter NaNs\n","    Returns:\n","        DataFrame with columns replaced with their NaN-filtered versions\n","    \"\"\"\n","\n","    def get_rowIndex(row):\n","        \"\"\"Function intended for applying across df rows\n","\n","        Args:\n","            row (int): row\n","\n","        Returns:\n","            int: index of row\n","        \"\"\"\n","      \n","        return row.name\n","\n","    def compare_and_replace(orig_visits, dataset_row_idx, school_zip):\n","        \"\"\"Function intended for applying across df rows\n","         Selectively replaces NaNs with 0's\n","        Args:\n","            orig_visits: original column that needs to be filtered\n","            dataset_row_idx: column with row indices for the entire df\n","            school_zip: column with school zips\n","\n","        Returns:\n","            float or NaN\n","        \"\"\"\n","        \n","        # school zip + zip idx\n","        first_val_row_idx = dict_row_idx[school_zip]\n","        zip_idx = dict_zip_idx[school_zip]\n","        max_idx = dict_max_zipindex_per_zip[school_zip]\n","        difference = max_idx - zip_idx + 1\n","\n","        # check the school zip first\n","        if dataset_row_idx < first_val_row_idx:\n","            orig_visits = orig_visits\n","        elif (dataset_row_idx >= first_val_row_idx) and (dataset_row_idx <=  first_val_row_idx + difference):\n","            if pd.isnull(orig_visits):\n","                orig_visits = 0\n","            else:\n","                orig_visits = orig_visits\n","        return orig_visits\n","        \n","    # group df by school_zip, year_month\n","    df_grouped_schools = df.groupby(['school_zip', 'year_month']).tail(1)\n","\n","    #df_grouped_schools['points_rank'] = df.groupby(['team'])['points'].rank('dense', ascending=False)\n","    unique_school_zips = list(df_grouped_schools['school_zip'].unique())\n","\n","    # generate overall row index\n","    df_grouped_schools['rowIndex'] = df_grouped_schools.apply(get_rowIndex, axis=1)\n","\n","    # generate row indices that rest per school zip\n","    df_grouped_schools['zipIndex'] = df_grouped_schools.groupby(['school_zip'])['year_month'].rank('first', ascending=True).astype(int)\n","    df_grouped_schools['zipIndex'] = df_grouped_schools['zipIndex'] - 1\n","\n","    # generate dictionary that gets max index per school zip\n","    dict_max_zipindex_per_zip = {}\n","    for i in unique_school_zips:\n","        dict_max_zipindex_per_zip[i] = df_grouped_schools[df_grouped_schools['school_zip']==i]['zipIndex'].max()\n","\n","    for i in visits_cols:\n","        dict_zip_idx = {}\n","        dict_row_idx = {}\n","        for j in unique_school_zips:\n","            temp = df_grouped_schools[df_grouped_schools['school_zip']==j]\n","            #display(temp)\n","            #temp['rowIndex'] = temp.apply(get_rowIndex, axis=1)\n","            visits_series = pd.Series(temp[i]) # one school zip, filtered to 1 health outcome\n","            #display(visits_series)\n","            bool_not_null = visits_series.notnull()\n","            all_indices_not_null = np.where(bool_not_null)[0]\n","\n","            # save index of the first non-NaN value within the zipcode indices\n","            # if everything every value for zip is NaN, set value to # of records in df\n","            try:\n","                groupby_index = all_indices_not_null[0]\n","            except IndexError:\n","                groupby_index = df_grouped_schools.shape[0]\n","            dict_zip_idx[j] = groupby_index\n","            \n","            # save index of the row from whole dataset; set valye to # of records in df if not\n","            try:\n","                row_idx = temp.loc[temp['zipIndex'] == groupby_index, 'rowIndex'].values[0]\n","            except IndexError:\n","                row_idx = df_grouped_schools.shape[0]\n","            dict_row_idx[j] = row_idx\n","        \n","        df_grouped_schools[i] = df_grouped_schools.apply(lambda row: compare_and_replace(row[i], row['rowIndex'], row['school_zip']), axis=1)\n","\n","    # drop rowIndex and zipIndex cols\n","    df_grouped_schools.drop(columns=['rowIndex', 'zipIndex'], inplace=True)\n","\n","    return df_grouped_schools"]},{"cell_type":"markdown","metadata":{"id":"Al805eKdNAq1"},"source":["Med data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-IdwjVDWNAq1"},"outputs":[],"source":["# med data:\n","\n","# get all distinct patzip_year_month\n","all_pats = df1['patzip_year_month'].to_list() + \\\n","  df2['patzip_year_month'].to_list() + \\\n","  df3['patzip_year_month'].to_list() + \\\n","  df4['patzip_year_month'].to_list() + \\\n","  df5['patzip_year_month'].to_list() \n","all_pats = list(set(all_pats))\n","df_med = pd.DataFrame({'patzip_year_month': all_pats})\n","\n","# rename columns more intuitively\n","df1 = df1.rename(columns={'number_of_visits': 'number_of_visits_hem_cancers'})\n","df2 = df2.rename(columns={'number_of_visits': 'number_of_visits_vasc'})\n","df3 = df3.rename(columns={'number_of_visits': 'number_of_visits_diab'})\n","df4 = df4.rename(columns={'number_of_visits': 'number_of_visits_resp_cardio'})\n","df5 = df5.rename(columns={'number_of_visits': 'number_of_visits_injuries'})\n","\n","# now join all the diagnoses on this dataset\n","df_med = df_med\\\n","  .merge(df1, on='patzip_year_month', how='left')\\\n","  .merge(df2, on='patzip_year_month', how='left')\\\n","  .merge(df3, on='patzip_year_month', how='left')\\\n","  .merge(df4, on='patzip_year_month', how='left')\\\n","  .merge(df5, on='patzip_year_month', how='left')\n","\n","# join data\n","if isinstance(df.year_month[0], str):\n","  # if year month is still a string, convert it to datetime\n","  # don't try if already converted\n","    df['year_month'] = df['year_month'].map(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n","\n","df['zip_year_month'] = df['school_zip'].astype(str) + '-' +\\\n","  df['year_month'].dt.year.astype(str) + '-' +\\\n","  df['year_month'].dt.month.astype(str)\n","\n","df = pd.merge(df, df_med, left_on='zip_year_month', right_on='patzip_year_month', how='left')\n","df = df.drop(columns = 'Unnamed: 0')\n","\n","# for missing med data, assume there were 0 cases:\n","med_vars = ['hematopoietic_cancers', 'number_of_visits_hem_cancers', \n","  'pediatric_vasculitis', 'number_of_visits_vasc', \n","  'type_1_diabetes', 'number_of_visits_diab',\n","  'resp_cardio', 'number_of_visits_resp_cardio',\n","  'injuries_accidents', 'number_of_visits_injuries'\n","  ]\n","\n","\n","# for var in med_vars:\n","#   df[var] = df[var].fillna(0)\n","\n","\n","# df.sort_values(['school_zip', 'year_month'], inplace=True)\n","\n","# Insert code here to populate na's for each HO with 0, only if there was a HO in this zipcode before\n","df = filter_nans(df, visits_cols = ['number_of_visits_hem_cancers', 'number_of_visits_vasc', \n","'number_of_visits_diab', 'number_of_visits_resp_cardio', 'number_of_visits_injuries'])\n","\n","\n","# fixing month datatype\n","df['month'] = df['month'].astype(str)\n","\n","# Create response variables, which is visits / population\n","df['y_hematopoietic'] = 1000 * df['number_of_visits_hem_cancers'] / df['total_pop_under19']\n","df['y_vasculitis'] = 1000 * df['number_of_visits_vasc'] / df['total_pop_under19']\n","df['y_diabetes'] = 1000 * df['number_of_visits_diab'] / df['total_pop_under19']\n","df['y_resp_cardio'] = 1000 * df['number_of_visits_resp_cardio'] / df['total_pop_under19']\n","df['y_injuries'] = 1000 * df['number_of_visits_injuries'] / df['total_pop_under19']\n","\n","# Create an option for a logged version of the treatment var (log(1+x)). this makes it normally distributed \n","df['pm25_log'] = np.log1p(df['pm25'])\n","\n","# create year trend feature\n","df['year_trend'] = df['year'] - 1999\n","\n","# create county_month\n","df['county_month'] = df.apply(lambda df: df['month'].rjust(2, '0') + '_' + df['school_county_v2'], axis=1)\n","\n","# create year_month_county (in case we want to just direclty use this var for the interaction effects)\n","df['year_month_county'] = df.apply(lambda df: str(df['year']) + '_' + df['month'] + '_' + df['school_county_v2'], axis=1)\n","\n","# no need to one hot encode anymore, b/c data is already encoded \n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZreYVPuaNAq1"},"source":["### Make Rolling HO Sum Columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hwd76qYSNAq1"},"outputs":[],"source":["# sort data on date\n","df = df.sort_values('year_month').reset_index(drop=True)\n","\n","# train/test split \n","# keep 2018 as the held out test set \n","df_test = df[df.year == 2018]\n","df = df[df.year != 2018]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7IpvUbUINAq2","outputId":"555d9703-8911-490d-b036-5bb1f5954704","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669605763367,"user_tz":420,"elapsed":11686,"user":{"displayName":"Trevor Johnson","userId":"10875792761423186902"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Columns added for health outcomes using 3 month window:\n","['number_of_visits_hem_cancers_fwd3', 'y_hematopoietic_fwd3', 'number_of_visits_hem_cancers_cent3', 'y_hematopoietic_cent3', 'number_of_visits_vasc_fwd3', 'y_vasculitis_fwd3', 'number_of_visits_vasc_cent3', 'y_vasculitis_cent3', 'number_of_visits_diab_fwd3', 'y_diabetes_fwd3', 'number_of_visits_diab_cent3', 'y_diabetes_cent3', 'number_of_visits_resp_cardio_fwd3', 'y_resp_cardio_fwd3', 'number_of_visits_resp_cardio_cent3', 'y_resp_cardio_cent3', 'number_of_visits_injuries_fwd3', 'y_injuries_fwd3', 'number_of_visits_injuries_cent3', 'y_injuries_cent3']\n"]}],"source":["# get rolling n month sum\n","def create_rolling_sum(df, var_name:str = 'number_of_visits_hem_cancers', num_months=3, center_arg:bool = False):\n","  \"\"\"\n","    Creates rolling sums for the number of visits for a given health outcome. \n","    Overwrite your dataframe with the output.\n","    Function saves the result as a column into the dataframe with subscripts \n","    - '{var_name}_fwd{number of months}' for forward sums\n","    - '{var_name}_cent{number of months}' for centered sums\n","\n","    Function includes the current month as one of the months in num_months.\n","\n","    Dataframe input MUST be sorted by ['school_zip', 'year_month'] ahead of time.\n","\n","    `df = df.sort_values(['school_zip', 'year_month'])`\n","\n","    Suggested: filter out tail end of dates so rolling averages are not filled with imputed values.\n","\n","  Args:\n","      `df` (dataframe): dataframe having columns for 'school_zip', datetime 'year_month', and number of visits. Dataframe must be sorted by \n","      `var_name` (str, optional): health outcome number of visits. Defaults to 'number_of_visits_hem_cancers'.\n","      `num_months` (int, optional): Number of months to take rolling sum over. Defaults to 3.\n","      `center_arg` (bool, optional): If this sum should be centered on current month. Defaults to False.\n","\n","  Returns:\n","      `df_int`: returns dataframe with column added\n","  \"\"\"\n","  df_int = df.copy().sort_values(['school_zip', 'year_month']).reset_index(drop=True)\n","  \n","  if center_arg:\n","    df_int[f'{var_name}_cent{num_months}'] = df_int.groupby('school_zip')[var_name]\\\n","                                      .apply(lambda x:x.rolling(num_months, center=True).sum())\n","  else:\n","    df_int[f'{var_name}_fwd{num_months}'] = df_int.groupby('school_zip')[var_name]\\\n","                                      .apply(lambda x:x.rolling(num_months).sum().shift(1-num_months))\n","\n","  \n","  return df_int \n","\n","\n","df = df.sort_values(['school_zip', 'year_month'])\n","starting_cols = list(df.columns)\n","\n","num_visits_col_names = ['number_of_visits_hem_cancers', \n","  'number_of_visits_vasc', \n","  'number_of_visits_diab',\n","  'number_of_visits_resp_cardio',\n","  'number_of_visits_injuries'\n","  ]\n","\n","y_col_names = ['y_hematopoietic', \n","  'y_vasculitis', \n","  'y_diabetes',\n","  'y_resp_cardio',\n","  'y_injuries'\n","  ]\n","\n","# 3 months ---\n","n = 3 # specify number of months\n","\n","for health_outcome_y_col, health_outcome_visits_col in zip(y_col_names, num_visits_col_names):\n","    # forward looking columns\n","    df = create_rolling_sum(df=df, var_name=health_outcome_visits_col, num_months=n, center_arg=False)\n","    df[f'{health_outcome_y_col}_fwd{n}'] = 1000 * df[f'{health_outcome_visits_col}_fwd{n}'] / df['total_pop_under19']\n","\n","    # centered columns\n","    df = create_rolling_sum(df=df, var_name=health_outcome_visits_col, num_months=n, center_arg=True)\n","    df[f'{health_outcome_y_col}_cent{n}'] = 1000 * df[f'{health_outcome_visits_col}_cent{n}'] / df['total_pop_under19']\n","\n","\n","# print columns added\n","ending_cols = list(df.columns)\n","window_3months_columns = [c for c in ending_cols if c not in starting_cols]\n","print(f\"\\nColumns added for health outcomes using {n} month window:\\n{window_3months_columns}\")\n","starting_cols = list(df.columns)\n","\n","\n","# filter data to appropriate data range\n","df = df[df.year >= 2002]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VemVaQwRNAq2"},"outputs":[],"source":["# Select variables for modeling\n","date_var = 'year_month' \n","zip_var = 'school_zip'\n","y_var_s2 = 'y_hematopoietic' + HO_lag_input # need to change this so it runs on Cornelia's PC\n","\n","# stage 1 variables\n","instruments_cols = [predictor]\n","\n","stage_1_IVs = [s + IV_lead_input for s in instruments_cols]\n","stage_1_target = [target_name_s1]\n","\n","# stage 2 variables\n","stage_2_HO_targets = [s + HO_lag_input for s in y_col_names]\n","\n","num_vars = ['school_elevation_m', 'nearby_point_source_count', 'school_wspd', \\\n","            'tax_liability_per_capita', 'school_temperature', 'school_count', 'pm25_r6', 'pm25_r12']\n","counties = [i for i in df.columns if re.search('^school_county_v2_', i)]\n","months = [i for i in df.columns if re.search ('^month_', i)]\n","# potentially use county_month instead of the above \n","\n","xvars = num_vars + counties + months \n","yvar = [y_var_s2]"]},{"cell_type":"markdown","metadata":{"id":"XHRqBVJ1NAq2"},"source":["# xgb stage 1"]},{"cell_type":"markdown","metadata":{"id":"JdXcMMl9NAq2"},"source":["Setups"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eCAY_4jNAq2","outputId":"9d1023e2-f01f-4f20-b218-90723b42a84a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669605763644,"user_tz":420,"elapsed":8,"user":{"displayName":"Trevor Johnson","userId":"10875792761423186902"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["basics:\n","['school_county_v2_alameda', 'school_county_v2_alpine', 'school_county_v2_amador', 'school_county_v2_butte', 'school_county_v2_calaveras', 'school_county_v2_colusa', 'school_county_v2_contra_costa', 'school_county_v2_del_norte', 'school_county_v2_el_dorado', 'school_county_v2_fresno', 'school_county_v2_glenn', 'school_county_v2_humboldt', 'school_county_v2_imperial', 'school_county_v2_inyo', 'school_county_v2_kern', 'school_county_v2_kings', 'school_county_v2_lake', 'school_county_v2_lassen', 'school_county_v2_los_angeles', 'school_county_v2_madera', 'school_county_v2_marin', 'school_county_v2_mariposa', 'school_county_v2_mendocino', 'school_county_v2_merced', 'school_county_v2_modoc', 'school_county_v2_mono', 'school_county_v2_monterey', 'school_county_v2_napa', 'school_county_v2_nevada', 'school_county_v2_orange', 'school_county_v2_placer', 'school_county_v2_plumas', 'school_county_v2_riverside', 'school_county_v2_sacramento', 'school_county_v2_san_benito', 'school_county_v2_san_bernardino', 'school_county_v2_san_diego', 'school_county_v2_san_francisco', 'school_county_v2_san_joaquin', 'school_county_v2_san_luis_obispo', 'school_county_v2_san_mateo', 'school_county_v2_santa_barbara', 'school_county_v2_santa_clara', 'school_county_v2_santa_cruz', 'school_county_v2_shasta', 'school_county_v2_sierra', 'school_county_v2_siskiyou', 'school_county_v2_solano', 'school_county_v2_sonoma', 'school_county_v2_stanislaus', 'school_county_v2_sutter', 'school_county_v2_tehama', 'school_county_v2_trinity', 'school_county_v2_tulare', 'school_county_v2_tuolumne', 'school_county_v2_ventura', 'school_county_v2_yolo', 'school_county_v2_yuba', 'month_01', 'month_02', 'month_03', 'month_04', 'month_05', 'month_06', 'month_07', 'month_08', 'month_09', 'month_10', 'month_11', 'month_12', 'year_trend']\n","\n","env:\n","['avg_temp_r9', 'avg_elevation_diff_m']\n","\n","Fixed effects are:\n","['school_county_v2_alameda', 'school_county_v2_alpine', 'school_county_v2_amador', 'school_county_v2_butte', 'school_county_v2_calaveras', 'school_county_v2_colusa', 'school_county_v2_contra_costa', 'school_county_v2_del_norte', 'school_county_v2_el_dorado', 'school_county_v2_fresno', 'school_county_v2_glenn', 'school_county_v2_humboldt', 'school_county_v2_imperial', 'school_county_v2_inyo', 'school_county_v2_kern', 'school_county_v2_kings', 'school_county_v2_lake', 'school_county_v2_lassen', 'school_county_v2_los_angeles', 'school_county_v2_madera', 'school_county_v2_marin', 'school_county_v2_mariposa', 'school_county_v2_mendocino', 'school_county_v2_merced', 'school_county_v2_modoc', 'school_county_v2_mono', 'school_county_v2_monterey', 'school_county_v2_napa', 'school_county_v2_nevada', 'school_county_v2_orange', 'school_county_v2_placer', 'school_county_v2_plumas', 'school_county_v2_riverside', 'school_county_v2_sacramento', 'school_county_v2_san_benito', 'school_county_v2_san_bernardino', 'school_county_v2_san_diego', 'school_county_v2_san_francisco', 'school_county_v2_san_joaquin', 'school_county_v2_san_luis_obispo', 'school_county_v2_san_mateo', 'school_county_v2_santa_barbara', 'school_county_v2_santa_clara', 'school_county_v2_santa_cruz', 'school_county_v2_shasta', 'school_county_v2_sierra', 'school_county_v2_siskiyou', 'school_county_v2_solano', 'school_county_v2_sonoma', 'school_county_v2_stanislaus', 'school_county_v2_sutter', 'school_county_v2_tehama', 'school_county_v2_trinity', 'school_county_v2_tulare', 'school_county_v2_tuolumne', 'school_county_v2_ventura', 'school_county_v2_yolo', 'school_county_v2_yuba', 'month_01', 'month_02', 'month_03', 'month_04', 'month_05', 'month_06', 'month_07', 'month_08', 'month_09', 'month_10', 'month_11', 'month_12', 'year_trend', 'avg_temp_r9', 'avg_elevation_diff_m', 'ca_agi_per_returns', 'total_population']\n"]}],"source":["basics = counties + months + ['year_trend']\n","env = ['avg_temp'+IV_lead_input , 'avg_elevation_diff_m']\n","\n","if FE_set_num == 1:\n","    # FE Set 1\n","    adds = []\n","elif FE_set_num == 2:\n","    # FE Set 2\n","    adds = ['ca_agi_per_returns', 'total_population']\n","elif FE_set_num == 3:\n","    # FE Set 3\n","    adds = ['school_count', 'total_population']\n","elif FE_set_num == 4:\n","    # FE Set 4\n","    adds = ['total_population', 'avg_count_ps_within_5km']\n","\n","fixed_effects_cols = basics + env + adds\n","\n","print(\"basics:\\n{}\\n\".format(basics))\n","print(\"env:\\n{}\\n\".format(env))\n","\n","print(\"Fixed effects are:\\n{}\".format(fixed_effects_cols))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Y-FqPQKNAq2","outputId":"40fc95d5-3593-4e12-88d0-bdde439ed65d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669605763645,"user_tz":420,"elapsed":7,"user":{"displayName":"Trevor Johnson","userId":"10875792761423186902"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n","\n","Stage 1 Variables---\n","\n","target_name_s1: pm25_r9\n","\n","predictor_name_s1: Izmy_v3_normed_D_and_TPY_r9\n","\n","Fixed Effects (fixed_effects_cols): ['school_county_v2_alameda', 'school_county_v2_alpine', 'school_county_v2_amador', 'school_county_v2_butte', 'school_county_v2_calaveras', 'school_county_v2_colusa', 'school_county_v2_contra_costa', 'school_county_v2_del_norte', 'school_county_v2_el_dorado', 'school_county_v2_fresno', 'school_county_v2_glenn', 'school_county_v2_humboldt', 'school_county_v2_imperial', 'school_county_v2_inyo', 'school_county_v2_kern', 'school_county_v2_kings', 'school_county_v2_lake', 'school_county_v2_lassen', 'school_county_v2_los_angeles', 'school_county_v2_madera', 'school_county_v2_marin', 'school_county_v2_mariposa', 'school_county_v2_mendocino', 'school_county_v2_merced', 'school_county_v2_modoc', 'school_county_v2_mono', 'school_county_v2_monterey', 'school_county_v2_napa', 'school_county_v2_nevada', 'school_county_v2_orange', 'school_county_v2_placer', 'school_county_v2_plumas', 'school_county_v2_riverside', 'school_county_v2_sacramento', 'school_county_v2_san_benito', 'school_county_v2_san_bernardino', 'school_county_v2_san_diego', 'school_county_v2_san_francisco', 'school_county_v2_san_joaquin', 'school_county_v2_san_luis_obispo', 'school_county_v2_san_mateo', 'school_county_v2_santa_barbara', 'school_county_v2_santa_clara', 'school_county_v2_santa_cruz', 'school_county_v2_shasta', 'school_county_v2_sierra', 'school_county_v2_siskiyou', 'school_county_v2_solano', 'school_county_v2_sonoma', 'school_county_v2_stanislaus', 'school_county_v2_sutter', 'school_county_v2_tehama', 'school_county_v2_trinity', 'school_county_v2_tulare', 'school_county_v2_tuolumne', 'school_county_v2_ventura', 'school_county_v2_yolo', 'school_county_v2_yuba', 'month_01', 'month_02', 'month_03', 'month_04', 'month_05', 'month_06', 'month_07', 'month_08', 'month_09', 'month_10', 'month_11', 'month_12', 'year_trend', 'avg_temp_r9', 'avg_elevation_diff_m', 'ca_agi_per_returns', 'total_population']\n","\n","Saving predictions (target_name_s1_predictions) as `pm25_r9_hat`\n","Size of df before filtering for modeling: (262674, 205)\n","Size of df after filtering for modeling: (262450, 205)\n"]}],"source":["# check if all these columns are in the dataframe\n","in_col_list = [True if i in df.columns else i for i in fixed_effects_cols ]\n","\n","print(f\"{in_col_list}\")\n","\n","print(f\"\\nStage 1 Variables---\\n\")\n","print(f\"target_name_s1: {target_name_s1}\\n\")\n","print(f\"predictor_name_s1: {predictor_name_s1}\\n\")\n","print(f\"Fixed Effects (fixed_effects_cols): {fixed_effects_cols}\\n\")\n","\n","target_name_s1_predictions = target_name_s1 + \"_hat\"\n","print(f\"Saving predictions (target_name_s1_predictions) as `{target_name_s1_predictions}`\")\n","\n","# create a df for modeling stage 1: drops nulls in all columns used\n","df_model_s1 = df.dropna(subset=([target_name_s1, predictor_name_s1] + fixed_effects_cols))\n","\n","print(f\"Size of df before filtering for modeling: {df.shape}\")\n","print(f\"Size of df after filtering for modeling: {df_model_s1.shape}\")\n","\n","\n","X_s1 = df_model_s1[[predictor_name_s1] + fixed_effects_cols]\n","y_s1 = df_model_s1[target_name_s1]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iEI7b5EXNAq2"},"outputs":[],"source":["# need to sort the values and use the index to sort things\n","df_model_s1.sort_values(by=['year_month'], inplace=True)\n","df_model_s1 = df_model_s1.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tW8rLsIDNAq2"},"outputs":[],"source":["# sklearn api version\n","def time_series_cv(\n","  df: pd.DataFrame, \n","  xvars: list, \n","  yvar: str, \n","  hyperparams: dict = {'max_depth': [1, 5, 10], 'subsample': [.8, 1], 'eta': [.1, .3]}, \n","  search_type='grid', \n","  folds=5, \n","  verbose=1):\n","\n","  ''' \n","  Inputs:\n","  - df: dataframe of your training data\n","  - xvars: a list of all the xvars to pass to xgboost\n","  - yvar: string of your target variable\n","  - verbose: optionality for diff amounts of printouts. Can be 0, 1, 2. 0 = silent, 1 = update after each fold, 2 = update after every single hyperparam combination. \n","  - hyperparams: this must be a dictionary of lists. So each key is a xgb hyperparam, then it must have a list of values to tune with. \n","    See the default for an example. Can put in an arbitrary number of hyperparam options. \n","  \n","  Output:\n","  - dictionary with the following keys: ['fold', 'hyperparams', 'rmse_train', 'rmse_test']. \n","  eval(best_hyperparams)\n","  - dictionary with the best hyperparameters to retrain model\n","  '''\n","\n","  # this dictionary will hold all the final results\n","  final_res = {'fold':[], 'hyperparams':[], 'rmse_train': [], 'rmse_test': [],\n","                'huber_loss_train': [], 'huber_loss_test': []}\n","\n","  # get only necessary fields in df\n","  df = df[xvars + [yvar]]\n","\n","  # set up the time series split class, to do an expanding window cross fold. \n","  tss = TimeSeriesSplit(n_splits=folds)\n","  tss_folds = tss.split(df)\n","  all_folds = [i for i in tss_folds]\n","\n","  # get all combinations of hyperparams\n","  def expand_grid(hyperparams):\n","    keys = list(hyperparams.keys())\n","    hyperparams_df = pd.DataFrame(np.array(np.meshgrid(*[hyperparams[key_i] for key_i in keys])).T.reshape(-1, len(keys)))\n","    hyperparams_df.columns = keys \n","    return hyperparams_df\n","\n","  df_hyperparams = expand_grid(hyperparams)\n","\n","  # loss functions\n","  def get_rmse(df_train, model):\n","    ytrue = df_train[yvar].values.flatten()\n","    yhat = model.predict(df_train.drop(columns=yvar))\n","    rmse = np.mean(((ytrue - yhat)**2)**.5)\n","    return rmse \n","  \n","  def get_huber_loss(df_train, model):\n","    # # Let the delta for Huber Loss be 2*standard deviation of non-zero entries for the y variable\n","    # twice_std = 2 * df_train[df_train[yvar] > 0][yvar].std  \n","\n","    # Let the delta for Huber Loss be 2*standard deviation of the y variable\n","    twice_std = 2 * df_train[yvar].std() \n","\n","    def huber_loss(y_actual,y_predicted,delta):\n","      # https://towardsdatascience.com/understanding-loss-functions-the-smart-way-904266e9393\n","      # approaches MSE for small error an approaches MAE in case of outliers.\n","      delta = 5\n","      total_points = y_actual.size\n","      total_error = 0\n","      for i in range(total_points):\n","        error = np.absolute(y_predicted[i] - y_actual[i])\n","        if error < delta:\n","          huber_error = (error*error)/2\n","        else:\n","          huber_error = delta*(error - (0.5*delta))\n","        total_error+=huber_error\n","      total_huber_error = total_error/total_points\n","      return total_huber_error  # mean huber_loss\n","\n","    ytrue = df_train[yvar].values.flatten()\n","    yhat = model.predict(df_train.drop(columns=yvar))\n","\n","    huber_loss_val = huber_loss(y_actual=ytrue, y_predicted=yhat, delta=twice_std)\n","\n","    return huber_loss_val\n","\n","  # loop over each expanding time series window\n","  for fold_count,fold in enumerate(all_folds):\n","    if verbose > 0:\n","      print('Working on fold {}/{}'.format(fold_count+1, folds))\n","\n","    df_train = df.loc[fold[0]]\n","    df_test = df.loc[fold[1]]\n","\n","    # within each time series cross fold, perform a grid search with all hyperparam combinations and evaluate results. \n","    if search_type == 'grid':\n","      for param_set_i in range(df_hyperparams.shape[0]):\n","        hyperparams_i = {x:y for x,y in zip(df_hyperparams.columns, df_hyperparams.loc[param_set_i].to_list())}\n","        \n","        # fix datatype for some vars\n","        def fix_int(var, hyperparams_i):\n","          if var in hyperparams_i.keys():\n","            hyperparams_i[var] = int(hyperparams_i[var])\n","          \n","          return hyperparams_i\n","        \n","        hyperparams_i = fix_int('max_depth', hyperparams_i)\n","        hyperparams_i = fix_int('n_estimators', hyperparams_i)\n","\n","        # if adding hyperparams based on integeters, do this fix_int so it isnt converted to float\n","        \n","\n","        # fit xgb\n","        xgb_reg = xgb.XGBRegressor(booster=\"gbtree\", **hyperparams_i, verbosity=0, random_state=20)\n","        xgb_reg = xgb_reg.fit(X=df_train[xvars], y=df_train[yvar], eval_set=[(df_test[xvars], df_test[yvar])], verbose=0)\n","        \n","        # save results\n","        rmse_train = get_rmse(df_train, xgb_reg)\n","        rmse_test = get_rmse(df_test, xgb_reg)\n","        huber_train = get_huber_loss(df_train, xgb_reg)\n","        huber_test = get_huber_loss(df_test, xgb_reg)\n","        final_res['fold'].append(fold_count)\n","        final_res['hyperparams'].append(hyperparams_i)\n","        final_res['rmse_train'].append(rmse_train)\n","        final_res['rmse_test'].append(rmse_test)\n","        final_res['huber_loss_train'].append(huber_train)\n","        final_res['huber_loss_test'].append(huber_test)\n","\n","        if verbose == 2:\n","          print('{}: rmse train: {:.3f}, rmse test: {:.3f}'.format(hyperparams_i, rmse_train, rmse_test))\n","\n","    elif search_type == 'random': \n","      pass \n","      # haven't done this yet\n","  \n","  # print out final best hyperparams before returning the output\n","  output2 = pd.DataFrame({\n","    'hyperparams': final_res['hyperparams'],\n","    'fold': final_res['fold'],\n","    'rmse_train': final_res['rmse_train'],\n","    'rmse_test': final_res['rmse_test']\n","  })\n","  output2['hyperparams'] = output2['hyperparams'].astype(str)\n","  output2 = output2.groupby('hyperparams')[['rmse_train', 'rmse_test']].mean().reset_index().sort_values('rmse_test')\n","  print('best hyperparams: {}'.format(output2.iloc[0,0]))\n","  print(f\"best RMSE test: {output2.iloc[0]['rmse_test']}\")\n","\n","  best_hyperparams = output2.iloc[0,0]\n","\n","  \n","  return final_res, eval(best_hyperparams)\n","  "]},{"cell_type":"markdown","metadata":{"id":"VZEwH-JxNAq3"},"source":["Running Sklearn CV function for Stage 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nPsuKpAyNAq3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669608952977,"user_tz":420,"elapsed":1,"user":{"displayName":"Trevor Johnson","userId":"10875792761423186902"}},"outputId":"97d5b5db-a4f0-4510-a10d-529e5568b86c"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Working on fold 1/3\n","Working on fold 2/3\n","Working on fold 3/3\n","best hyperparams: {'max_depth': 5, 'subsample': 0.7, 'eta': 0.1, 'n_estimators': 100}\n","best RMSE test: 1.6285160020685507\n"]}],"source":["output_s1, best_params_s1 = time_series_cv(df_model_s1, \n","  xvars = ([predictor_name_s1] + fixed_effects_cols), \n","  yvar = target_name_s1, \n","  hyperparams = {'max_depth': [3, 5], 'subsample': [.7, .8], 'eta': [.05, .1], 'n_estimators': [50, 75, 100]}, \n","  search_type = 'grid', \n","  folds = 3, \n","  verbose=1)"]},{"cell_type":"markdown","source":["# Documenting best hyperparams:\n","- predictor = 'Izmy_v3_normed_D_and_TPY', FE_set_num = 2, lead_time = '9', lag_time = '3', lag_style = 'fwd'\n","  - Combo 1: {'max_depth': [1, 2, 3], 'subsample': [.8, 1], 'eta': [.1], 'n_estimators': [10, 20, 50]}. best hyperparams: {'max_depth': 3, 'subsample': 0.8, 'eta': 0.1, 'n_estimators': 50}. RMSE test: 1.8994124148649831. \n","  - Combo 2: {'max_depth': [3, 5], 'subsample': [.7, .8], 'eta': [.05, .1], 'n_estimators': [50, 75, 100]}. hyperparams: {'max_depth': 5, 'subsample': 0.7, 'eta': 0.1, 'n_estimators': 100}. best RMSE test: 1.6285160020685507"],"metadata":{"id":"NbUF0oYOSh2i"}}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 ('w210_env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"b37bc99320db5ac87e487a0a73a079f690341dc989821c54010d9f7a6cf99c3c"}},"colab":{"provenance":[],"machine_shape":"hm"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}